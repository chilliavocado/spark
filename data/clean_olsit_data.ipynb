{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "root_path=Path(os.getcwd())\n",
    "source_path=root_path.joinpath('source')\n",
    "target_path=root_path.joinpath('cleaned')\n",
    "\n",
    "os.makedirs(source_path, exist_ok=True)\n",
    "os.makedirs(target_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers      = pd.read_csv(source_path.joinpath('olist_customers_dataset.csv'))\n",
    "# geolocation    = pd.read_csv(source_path.joinpath('olist_geolocation_dataset.csv'))\n",
    "orders         = pd.read_csv(source_path.joinpath('olist_orders_dataset.csv'))\n",
    "order_items    = pd.read_csv(source_path.joinpath('olist_order_items_dataset.csv'))\n",
    "# order_payments = pd.read_csv(source_path.joinpath('olist_order_payments_dataset.csv'))\n",
    "order_reviews  = pd.read_csv(source_path.joinpath('olist_order_reviews_dataset.csv'))\n",
    "products       = pd.read_csv(source_path.joinpath('olist_products_dataset.csv'))\n",
    "# sellers        = pd.read_csv(source_path.joinpath('olist_sellers_dataset.csv'))\n",
    "product_category_name_translation = pd.read_csv(source_path.joinpath('product_category_name_translation.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = products[['product_id','product_category_name']]\n",
    "products=(products\n",
    "          .merge(product_category_name_translation,how='left',on='product_category_name')\n",
    "          .drop(columns=['product_category_name'])\n",
    "          .rename(columns={'product_category_name_english':'product_category'})\n",
    "          )\n",
    "\n",
    "\n",
    "orders = (orders[['order_id', 'customer_id', 'order_purchase_timestamp']]\n",
    "          .rename(columns={'order_purchase_timestamp':'timestamp'})\n",
    "          )\n",
    "\n",
    "# Merge customers and orders tables together as customer_id and order_id is 1:1\n",
    "customers_orders=(customers\n",
    "                  .rename(columns={'customer_zip_code_prefix':'zip_code',\n",
    "                                   'customer_city':'city',\n",
    "                                   'customer_state':'state'})\n",
    "                  .merge(orders, how='inner', on='customer_id')\n",
    "            )\n",
    "\n",
    "\n",
    "# De-duplicate customer attributes, will be used later\n",
    "customers_unique = (customers_orders[['customer_unique_id','customer_id','zip_code','city','state']]\n",
    "                    .drop_duplicates(subset='customer_unique_id', keep='first')\n",
    "                    .drop(columns=['customer_id'])\n",
    "                    .sort_values(by=['customer_unique_id'])\n",
    "                    .reset_index(drop=True)\n",
    "                    # .reset_index()\n",
    "                    )\n",
    "\n",
    "# Aggregate order_items to find the value for each customer_id/order_id\n",
    "order_value = (order_items\n",
    "               .groupby('order_id')\n",
    "               .agg({'product_id':'count', 'price':'sum'})\n",
    "               .rename(columns={'product_id':'product_count', 'price':'value'})\n",
    "               .merge(customers_orders[['order_id','customer_unique_id']], how='inner', on='order_id')\n",
    "               .sort_values(by='product_count',ascending=False)\n",
    "               .reset_index()\n",
    "               )\n",
    "\n",
    "# Further aggregate order_value to customer_unique_id level\n",
    "customer_value = (order_value\n",
    "                  .groupby('customer_unique_id')\n",
    "                  .agg({'order_id':'count', 'product_count':'sum', 'value':'sum'})\n",
    "                  .rename(columns={'order_id':'order_count'})\n",
    "                  .merge(customers_unique, how='inner', on='customer_unique_id')\n",
    "                  .sort_values(by=['product_count'],ascending=False)\n",
    "                  .reset_index(drop=True)\n",
    "                  .reset_index()\n",
    "                  .rename(columns={'index':'customer_num_id'})\n",
    "                  )\n",
    "\n",
    "# Identify the top X customers to reduce the dataset to\n",
    "top_customers = (customer_value\n",
    "                 .head(50)\n",
    "                 )\n",
    "\n",
    "out_customers =(top_customers\n",
    "                .drop(columns=['customer_unique_id', 'order_count', 'product_count','value'])\n",
    "    )\n",
    "\n",
    "# \n",
    "top_order_items = (order_items[['order_id', 'order_item_id', 'product_id', 'price']]\n",
    "                   .merge(customers_orders[['timestamp','order_id','customer_unique_id']], how='inner', on='order_id')\n",
    "                   .merge(top_customers[['customer_unique_id','customer_num_id']], how='inner', on='customer_unique_id')\n",
    "                   .merge(products, how='left', on='product_id')\n",
    "                   .drop(columns='customer_unique_id')\n",
    "                   .sort_values(by=['timestamp','order_id'])\n",
    "                   .reset_index(drop=True)\n",
    "                   .reset_index()\n",
    "                   .rename(columns={'index':'order_num_id'})\n",
    "                   )\n",
    "\n",
    "\n",
    "top_order_items['timestamp'] = pd.to_datetime(top_order_items['timestamp']) + pd.to_timedelta(top_order_items['order_item_id'], unit='s')\n",
    "top_order_items['interaction_id'] = 'order-'+ top_order_items['order_num_id'].astype(str)\n",
    "top_order_items['review_score'] = 0\n",
    "top_order_items['type'] = 'buy'\n",
    "\n",
    "\n",
    "products_unique = (top_order_items[['product_id','product_category','price']]\n",
    "                   .drop_duplicates(subset='product_id', keep='first')\n",
    "                   .fillna(value={'product_category':'shrubbery'})\n",
    "                   .sort_values(by=['product_category'])\n",
    "                   .reset_index(drop=True)\n",
    "                   .reset_index()\n",
    "                   .rename(columns={'index':'product_num_id'})\n",
    "                   )\n",
    "\n",
    "products_unique['product_category_id'] = products_unique.groupby(['product_category']).cumcount()+1\n",
    "products_unique['product_name_id'] = products_unique['product_category'] + '-' + products_unique['product_category_id'].astype(str)\n",
    "\n",
    "out_category=(products_unique[['product_category']]\n",
    "                .drop_duplicates(subset='product_category', keep='first')\n",
    "                .reset_index(drop=True)\n",
    "                .reset_index()\n",
    "                .rename(columns={'index':'category_num_id'})\n",
    "    )\n",
    "\n",
    "out_products = (products_unique\n",
    "                .drop(columns=['product_id'])\n",
    "                .merge(category_unique, how='left', on='product_category')\n",
    "                )\n",
    "\n",
    "\n",
    "top_order_items=(top_order_items\n",
    "                 .drop(columns=['product_category', 'price'])\n",
    "                 .merge(products_unique, how='left', on='product_id')\n",
    "    )\n",
    "\n",
    "unique_order_products=(top_order_items[['order_id','order_item_id','product_num_id','customer_num_id']]\n",
    "                       .drop_duplicates(subset=['order_id','product_num_id'], keep='first')\n",
    "    )\n",
    "\n",
    "\n",
    "top_reviews =(order_reviews[['review_id','order_id','review_score','review_answer_timestamp']]\n",
    "              .rename(columns={'review_answer_timestamp':'timestamp'})\n",
    "              .merge(unique_order_products, how='inner', on='order_id')\n",
    "              .reset_index(drop=True)\n",
    "              .reset_index()\n",
    "              .rename(columns={'index':'review_num_id'})\n",
    "    )\n",
    "\n",
    "top_reviews['timestamp'] = pd.to_datetime(top_reviews['timestamp']) + pd.to_timedelta(top_reviews['order_item_id'], unit='s')\n",
    "top_reviews['interaction_id'] = 'review-'+ top_reviews['review_num_id'].astype(str)\n",
    "top_reviews['type'] = 'rate'\n",
    "top_reviews['value'] = 1\n",
    "\n",
    "out_interactions=(pd.concat([top_order_items[['timestamp','interaction_id','product_num_id','customer_num_id','review_score', 'type', 'price']].rename(columns={'price':'value'}),\n",
    "                        top_reviews[['timestamp','interaction_id','product_num_id','customer_num_id','review_score', 'type', 'value']].rename(columns={'price':'value'})\n",
    "                        ])\n",
    "                  .sort_values(by=['timestamp','interaction_id'])\n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_interactions.rename(columns={'interaction_id':'idx',\n",
    "                                 'timestamp':'timestamp',\n",
    "                                 'customer_num_id':'customer_idx',\n",
    "                                 'product_num_id':'product_idx',\n",
    "                                 'type':'type',\n",
    "                                 'value':'value',\n",
    "                                 'review_score':'review_score',\n",
    "                                 }\n",
    "                        ,inplace=True)\n",
    "\n",
    "out_customers.rename(columns={'customer_num_id':'idx',\n",
    "                              'city':'city',\n",
    "                              'zip_code':'zip_code',\n",
    "                              'state':'state',\n",
    "                                 }\n",
    "                        ,inplace=True)\n",
    "\n",
    "out_category.rename(columns={'category_num_id':'idx',\n",
    "                              'product_category':'name'\n",
    "                                 }\n",
    "                        ,inplace=True)\n",
    "\n",
    "out_products.rename(columns={'product_num_id':'idx',\n",
    "                             'product_name_id':'name',\n",
    "                             'product_category_id':'category_id',\n",
    "                             'product_category':'category',\n",
    "                             'price':'price',\n",
    "                                 }\n",
    "                        ,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_products['desc']=out_products['name']\n",
    "out_products['long_desc']=out_products['name']\n",
    "out_category['desc']=out_category['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_interactions.to_csv(target_path.joinpath('Interaction.csv'))\n",
    "out_customers.to_csv(target_path.joinpath('Customer.csv'))\n",
    "out_category.to_csv(target_path.joinpath('Category.csv'))\n",
    "out_products.to_csv(target_path.joinpath('Product.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
