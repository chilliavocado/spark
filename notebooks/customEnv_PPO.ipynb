{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import ast\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "from typing import List, Optional, Tuple, Dict, Any\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.utils import seeding\n",
    "from stable_baselines3 import SAC, PPO, A2C, DDPG, TD3, DQN\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.logger import configure\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Model Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customer:\n",
    "    def __init__(self, idx: int, zip_code: int, city: str, state: str, num_products: int):\n",
    "        self.idx = idx\n",
    "        self.zip_code = zip_code\n",
    "        self.city = city\n",
    "        self.state = state\n",
    "        self.views = [0] * num_products\n",
    "        self.likes = [0] * num_products\n",
    "        self.purchases = [0] * num_products\n",
    "        self.ratings = [0] * num_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Category:\n",
    "    def __init__(self, idx: int, name: str, desc: str):\n",
    "        self.idx = idx\n",
    "        self.name = name\n",
    "        self.desc = desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Product:\n",
    "    def __init__(self, idx: int, name: str, desc: str, long_desc: str, category: Category, price: float) -> None:\n",
    "        self.idx = idx\n",
    "        self.name = name\n",
    "        self.desc = desc\n",
    "        self.long_desc = long_desc\n",
    "        self.category = category\n",
    "        self.price = price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractionType(Enum):\n",
    "    NONE = \"none\"\n",
    "    VIEW = \"view\"\n",
    "    LIKE = \"like\"\n",
    "    BUY = \"buy\"\n",
    "    RATE = \"rate\"\n",
    "    EXIT = \"exit\"\n",
    "    SESSION_START = \"session_start\"\n",
    "    SESSION_CLOSE = \"session_close\"\n",
    "\n",
    "\n",
    "class Interaction:\n",
    "    def __init__(\n",
    "        self,\n",
    "        idx: str,\n",
    "        timestamp: datetime,\n",
    "        product_idx: int,\n",
    "        customer_idx: int,\n",
    "        type: InteractionType,\n",
    "        value: float = 0.0,\n",
    "        review_score: Optional[int] = None,\n",
    "    ):\n",
    "        self.idx = idx\n",
    "        self.timestamp = timestamp\n",
    "        self.product_idx = product_idx\n",
    "        self.customer_idx = customer_idx\n",
    "        self.type = type\n",
    "        self.value = value\n",
    "        self.review_score = review_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/cleaned/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_customers(num_products: int, interactions: List[Interaction], product_id_to_index: Dict[int, int], idxs: List[int] = []) -> List[Customer]:\n",
    "    customer_df = pd.read_csv(f\"{data_dir}Customer.csv\")\n",
    "\n",
    "    if idxs:\n",
    "        customer_df = customer_df[customer_df[\"idx\"].isin(idxs)]\n",
    "\n",
    "    # Reset index to get zero-based indices\n",
    "    customer_df.reset_index(drop=True, inplace=True)\n",
    "    customer_id_to_index = {row[\"idx\"]: idx for idx, row in customer_df.iterrows()}\n",
    "\n",
    "    # Create a dictionary to hold customer interactions\n",
    "    customer_interactions = {}\n",
    "    for interaction in interactions:\n",
    "        cust_id = interaction.customer_idx\n",
    "        if cust_id not in customer_id_to_index:\n",
    "            continue  # Skip if customer not found\n",
    "        cust_idx = customer_id_to_index[cust_id]\n",
    "\n",
    "        if cust_idx not in customer_interactions:\n",
    "            customer_interactions[cust_idx] = {\n",
    "                \"views\": [0] * num_products,\n",
    "                \"likes\": [0] * num_products,\n",
    "                \"purchases\": [0] * num_products,\n",
    "                \"ratings\": [0] * num_products,\n",
    "            }\n",
    "\n",
    "        product_idx = interaction.product_idx\n",
    "        if product_idx not in product_id_to_index:\n",
    "            continue  # Skip if product not found\n",
    "        prod_idx = product_id_to_index[product_idx]\n",
    "\n",
    "        if interaction.type == InteractionType.VIEW:\n",
    "            customer_interactions[cust_idx][\"views\"][prod_idx] += 1\n",
    "        elif interaction.type == InteractionType.LIKE:\n",
    "            customer_interactions[cust_idx][\"likes\"][prod_idx] += 1\n",
    "        elif interaction.type == InteractionType.BUY:\n",
    "            customer_interactions[cust_idx][\"purchases\"][prod_idx] += 1\n",
    "            customer_interactions[cust_idx][\"ratings\"][prod_idx] = interaction.review_score if interaction.review_score else 0\n",
    "        elif interaction.type == InteractionType.RATE:\n",
    "            customer_interactions[cust_idx][\"ratings\"][prod_idx] = interaction.review_score if interaction.review_score else 0\n",
    "\n",
    "    customers = []\n",
    "    for idx, row in customer_df.iterrows():\n",
    "        cust_idx = idx\n",
    "        # Initialize with interaction data if available\n",
    "        interactions_data = customer_interactions.get(cust_idx, {})\n",
    "        views = interactions_data.get(\"views\", [0] * num_products)\n",
    "        likes = interactions_data.get(\"likes\", [0] * num_products)\n",
    "        purchases = interactions_data.get(\"purchases\", [0] * num_products)\n",
    "        ratings = interactions_data.get(\"ratings\", [0] * num_products)\n",
    "\n",
    "        # Create customer instance\n",
    "        customer = Customer(idx=cust_idx, zip_code=row[\"zip_code\"], city=row[\"city\"], state=row[\"state\"], num_products=num_products)\n",
    "\n",
    "        # Assign interaction data\n",
    "        customer.views = views\n",
    "        customer.likes = likes\n",
    "        customer.purchases = purchases\n",
    "        customer.ratings = ratings\n",
    "        customers.append(customer)\n",
    "\n",
    "    return customers, customer_id_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_categories(idxs: List[int] = []) -> List[Category]:\n",
    "    category_df = pd.read_csv(f\"{data_dir}Category.csv\")\n",
    "    if idxs:\n",
    "        category_df = category_df[category_df[\"idx\"].isin(idxs)]\n",
    "\n",
    "    categories = [Category(idx=row[\"idx\"], name=row[\"name\"], desc=row[\"desc\"]) for _, row in category_df.iterrows()]\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_products(idxs: List[int] = []) -> Tuple[List[Product], float, Dict[int, int]]:\n",
    "    product_df = pd.read_csv(f\"{data_dir}Product.csv\")\n",
    "    category_df = pd.read_csv(f\"{data_dir}Category.csv\")\n",
    "\n",
    "    # Create a dictionary to map category IDs to Category objects\n",
    "    category_map = {row[\"idx\"]: Category(idx=row[\"idx\"], name=row[\"name\"], desc=row[\"desc\"]) for _, row in category_df.iterrows()}\n",
    "\n",
    "    if idxs:\n",
    "        product_df = product_df[product_df[\"idx\"].isin(idxs)]\n",
    "\n",
    "    # Reset index to get zero-based indices\n",
    "    product_df.reset_index(drop=True, inplace=True)\n",
    "    product_id_to_index = {row[\"idx\"]: idx for idx, row in product_df.iterrows()}\n",
    "\n",
    "    products = [\n",
    "        Product(\n",
    "            idx=idx,  # Use zero-based index\n",
    "            name=row[\"name\"],\n",
    "            desc=row[\"desc\"],\n",
    "            long_desc=row[\"long_desc\"],\n",
    "            category=category_map.get(row[\"category_num_id\"]),\n",
    "            price=row[\"price\"],\n",
    "        )\n",
    "        for idx, row in product_df.iterrows()\n",
    "    ]\n",
    "\n",
    "    # Calculate the maximum price for setting price levels\n",
    "    max_price = product_df[\"price\"].max()\n",
    "    return products, max_price, product_id_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_interactions(\n",
    "    product_id_to_index: Dict[int, int], customer_id_to_index: Dict[int, int], idxs: List[int] = [], customer_idxs: List[int] = [], k: int = 0\n",
    ") -> List[Interaction]:\n",
    "    interaction_df = pd.read_csv(f\"{data_dir}Interaction.csv\")\n",
    "\n",
    "    # Filter by index or customer if specified\n",
    "    if idxs:\n",
    "        interaction_df = interaction_df[interaction_df[\"idx\"].isin(idxs)]\n",
    "    elif customer_idxs:\n",
    "        interaction_df = interaction_df[interaction_df[\"customer_idx\"].isin(customer_idxs)]\n",
    "\n",
    "    # Limit to the last k interactions, sorted by timestamp\n",
    "    if k > 0:\n",
    "        interaction_df = interaction_df.sort_values(by=\"timestamp\", ascending=False).head(k)\n",
    "\n",
    "    # Process each interaction with proper parsing and index mapping\n",
    "    interactions = []\n",
    "    for _, row in interaction_df.iterrows():\n",
    "        cust_id = row[\"customer_idx\"]\n",
    "        prod_id = row[\"product_idx\"]\n",
    "\n",
    "        if cust_id not in customer_id_to_index or prod_id not in product_id_to_index:\n",
    "            continue  # Skip if customer or product not found\n",
    "\n",
    "        interaction = Interaction(\n",
    "            idx=row[\"idx\"],\n",
    "            timestamp=datetime.strptime(row[\"timestamp\"], \"%Y-%m-%d %H:%M:%S\"),\n",
    "            customer_idx=customer_id_to_index[cust_id],\n",
    "            product_idx=product_id_to_index[prod_id],\n",
    "            type=InteractionType(row[\"type\"]),\n",
    "            value=row[\"value\"],\n",
    "            review_score=row[\"review_score\"],\n",
    "        )\n",
    "        interactions.append(interaction)\n",
    "\n",
    "    return interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load products and create mappings\n",
    "products, max_price, product_id_to_index = load_products()\n",
    "num_products = len(products)\n",
    "\n",
    "# Create placeholder customer mapping (will be filled in load_customers)\n",
    "customer_id_to_index = {}\n",
    "\n",
    "# Load interactions with mappings\n",
    "interactions = load_interactions(product_id_to_index, customer_id_to_index)\n",
    "\n",
    "# Now load customers with mappings\n",
    "customers, customer_id_to_index = load_customers(num_products, interactions, product_id_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommendationEnv(gym.Env):\n",
    "    def __init__(self, users: List[Customer], products: List[Product], top_k: int, max_price: float, price_interval: int = 500):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize users and products data\n",
    "        self.users = users\n",
    "        self.products = products\n",
    "        self.num_products = len(products)\n",
    "        self.top_k = top_k  # Number of top recommendations\n",
    "        self.user_idx = 0  # Index of the current user\n",
    "        self.current_step = 0  # Step count in the current episode\n",
    "        self.categories = load_categories()  # Load category data\n",
    "        self.num_categories = len(self.categories)\n",
    "        self.possible_interactions = [\n",
    "            InteractionType.NONE,\n",
    "            InteractionType.VIEW,\n",
    "            InteractionType.LIKE,\n",
    "            InteractionType.BUY,\n",
    "            InteractionType.RATE,\n",
    "            InteractionType.SESSION_CLOSE,\n",
    "        ]\n",
    "\n",
    "        # Define price levels based on max price and price interval\n",
    "        self.num_price_levels = int(np.ceil(max_price / price_interval))\n",
    "        self.price_interval = price_interval\n",
    "\n",
    "        # Initialize the random number generator\n",
    "        self.seed()\n",
    "\n",
    "        # Define the action space\n",
    "        self.action_space = spaces.Discrete(self.num_products)\n",
    "\n",
    "        # Define the observation space\n",
    "        self.observation_space = spaces.Dict(\n",
    "            {\n",
    "                \"pref_prod\": spaces.Box(low=0, high=1, shape=(self.num_products,), dtype=np.float32),\n",
    "                \"pref_cat\": spaces.Box(low=0, high=1, shape=(self.num_categories,), dtype=np.float32),\n",
    "                \"purchase\": spaces.Box(low=0, high=1, shape=(self.num_products,), dtype=np.float32),\n",
    "                \"viewed\": spaces.Box(low=0, high=1, shape=(self.num_products,), dtype=np.float32),\n",
    "                \"liked\": spaces.Box(low=0, high=1, shape=(self.num_products,), dtype=np.float32),\n",
    "                \"ratings\": spaces.Box(low=0, high=5, shape=(self.num_products,), dtype=np.float32),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def reset(self):\n",
    "        # Reset the environment to start a new episode\n",
    "        self.user_idx = self.np_random.integers(0, len(self.users))\n",
    "        self.current_step = 0\n",
    "        return self._get_observation()\n",
    "\n",
    "    def step(self, action):\n",
    "        # Execute one time step within the environment\n",
    "        self.current_step += 1  # Increment step count\n",
    "        user = self.users[self.user_idx]  # Get the current user\n",
    "\n",
    "        # Decode the action\n",
    "        decoded_action = self.decode_action(action)\n",
    "        recommended_product_idx = decoded_action[\"product_idx\"]\n",
    "\n",
    "        # Calculate the probability of each interaction type based on user preferences\n",
    "        product_pref = self._get_product_preferences(user)[recommended_product_idx]\n",
    "        interaction_probs = self._calculate_interaction_probabilities(product_pref)\n",
    "\n",
    "        # Simulate user interaction based on probabilities\n",
    "        interaction_type = self.np_random.choice(a=self.possible_interactions, p=interaction_probs)\n",
    "\n",
    "        # Define rating_value based on interaction_type\n",
    "        rating_value = self.np_random.integers(1, 6) if interaction_type == InteractionType.RATE else 0\n",
    "\n",
    "        # Calculate the reward and check if the episode is done\n",
    "        reward = self._calculate_reward(interaction_type, rating_value)\n",
    "        done = interaction_type == InteractionType.SESSION_CLOSE  # Episode ends if session is closed\n",
    "\n",
    "        # Update the user's observation based on the interaction\n",
    "        obs = self._update_observation(recommended_product_idx, interaction_type, rating_value)\n",
    "\n",
    "        return obs, reward, done, {}\n",
    "\n",
    "    def decode_action(self, action):\n",
    "        # Action directly corresponds to product index\n",
    "        product_idx = action\n",
    "        return {\"product_idx\": product_idx}\n",
    "\n",
    "    def _calculate_interaction_probabilities(self, product_pref):\n",
    "        # Ensure product_pref is within [0, 1]\n",
    "        product_pref = np.clip(product_pref, 0.0, 1.0)\n",
    "\n",
    "        # Example probabilities based on product preference\n",
    "        base_prob = 0.05  # Adjusted base probability\n",
    "        interaction_probs = {\n",
    "            InteractionType.VIEW: base_prob + 0.2 * product_pref,\n",
    "            InteractionType.LIKE: base_prob + 0.15 * product_pref,\n",
    "            InteractionType.BUY: base_prob + 0.1 * product_pref,\n",
    "            InteractionType.RATE: base_prob + 0.05 * product_pref,\n",
    "            InteractionType.SESSION_CLOSE: 0.05,  # Fixed small probability\n",
    "        }\n",
    "        # Compute total probability so far\n",
    "        total_prob = sum(interaction_probs.values())\n",
    "        # Compute NONE probability as the remaining probability\n",
    "        interaction_probs[InteractionType.NONE] = max(0.0, 1.0 - total_prob)\n",
    "        # Ensure all probabilities are non-negative\n",
    "        interaction_probs = {k: max(0.0, v) for k, v in interaction_probs.items()}\n",
    "\n",
    "        # Get probabilities in the order of possible_interactions\n",
    "        probs = [interaction_probs[itype] for itype in self.possible_interactions]\n",
    "\n",
    "        # Normalize probabilities\n",
    "        total = sum(probs)\n",
    "        if total == 0:\n",
    "            # Handle the case where all probabilities are zero\n",
    "            probs = [1.0 / len(probs)] * len(probs)\n",
    "        else:\n",
    "            probs = [prob / total for prob in probs]\n",
    "\n",
    "        return probs\n",
    "\n",
    "    def _calculate_reward(self, interaction_type, rating_value):\n",
    "        # Define rewards based on interaction type and rating\n",
    "        if interaction_type == InteractionType.NONE:\n",
    "            return -1\n",
    "        elif interaction_type == InteractionType.VIEW:\n",
    "            return 1\n",
    "        elif interaction_type == InteractionType.LIKE:\n",
    "            return 3\n",
    "        elif interaction_type == InteractionType.BUY:\n",
    "            return 20\n",
    "        elif interaction_type == InteractionType.RATE:\n",
    "            return (rating_value - 3) * 2  # Encourage high ratings\n",
    "        elif interaction_type == InteractionType.SESSION_CLOSE:\n",
    "            return -1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def _update_observation(self, product_idx, interaction_type, rating_value):\n",
    "        # Update the user's interaction data based on the interaction\n",
    "        user = self.users[self.user_idx]\n",
    "\n",
    "        if interaction_type == InteractionType.VIEW:\n",
    "            user.views[product_idx] += 1\n",
    "        elif interaction_type == InteractionType.LIKE:\n",
    "            user.likes[product_idx] += 1\n",
    "        elif interaction_type == InteractionType.BUY:\n",
    "            user.purchases[product_idx] += 1\n",
    "        elif interaction_type == InteractionType.RATE:\n",
    "            user.ratings[product_idx] = rating_value\n",
    "\n",
    "        # Return the updated observation\n",
    "        return self._get_observation()\n",
    "\n",
    "    def _get_observation(self):\n",
    "        # Construct the observation dictionary\n",
    "        user = self.users[self.user_idx]\n",
    "        max_views = max(user.views) if max(user.views) > 0 else 1\n",
    "        max_purchases = max(user.purchases) if max(user.purchases) > 0 else 1\n",
    "        max_likes = max(user.likes) if max(user.likes) > 0 else 1\n",
    "\n",
    "        observation = {\n",
    "            \"pref_prod\": self._get_product_preferences(user),\n",
    "            \"pref_cat\": self._get_category_preferences(user),\n",
    "            \"purchase\": np.array(user.purchases, dtype=np.float32) / max_purchases,\n",
    "            \"viewed\": np.array(user.views, dtype=np.float32) / max_views,\n",
    "            \"liked\": np.array(user.likes, dtype=np.float32) / max_likes,\n",
    "            \"ratings\": np.array(user.ratings, dtype=np.float32),\n",
    "        }\n",
    "        return observation\n",
    "\n",
    "    def _get_product_preferences(self, user):\n",
    "        # Calculate dynamic maximums for normalization\n",
    "        max_view = max(user.views) if max(user.views) > 0 else 1\n",
    "        max_purchase = max(user.purchases) if max(user.purchases) > 0 else 1\n",
    "        max_like = max(user.likes) if max(user.likes) > 0 else 1\n",
    "        max_rating = max(user.ratings) if max(user.ratings) > 0 else 5\n",
    "\n",
    "        # Calculate preferences dynamically\n",
    "        view_pref = np.array(user.views, dtype=np.float32) / max_view\n",
    "        purchase_pref = np.array(user.purchases, dtype=np.float32) / max_purchase\n",
    "        like_pref = np.array(user.likes, dtype=np.float32) / max_like\n",
    "        rate_pref = (np.array(user.ratings, dtype=np.float32) - 3.0) / max_rating\n",
    "\n",
    "        # Combine preferences and normalize\n",
    "        product_pref = view_pref + purchase_pref + like_pref + rate_pref\n",
    "        max_pref = np.max(product_pref) if np.max(product_pref) > 0 else 1\n",
    "        product_pref = np.clip(product_pref / max_pref, 0.0, 1.0)\n",
    "\n",
    "        return product_pref\n",
    "\n",
    "    def _get_category_preferences(self, user):\n",
    "        # Calculate category preferences by summing interactions per category\n",
    "        category_pref = np.zeros(self.num_categories, dtype=np.float32)\n",
    "        for product_idx in range(self.num_products):\n",
    "            category = self.products[product_idx].category\n",
    "            if category is not None:\n",
    "                category_idx = category.idx  # Assuming category.idx is zero-based\n",
    "                category_pref[category_idx] += user.views[product_idx] + user.purchases[product_idx]\n",
    "        total_pref = np.sum(category_pref)\n",
    "        if total_pref > 0:\n",
    "            category_pref = category_pref / total_pref\n",
    "        return category_pref\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        # Optional: implement visualization if needed\n",
    "        print(f\"Current User Index: {self.user_idx}\")\n",
    "        print(f\"Step: {self.current_step}\")\n",
    "\n",
    "    def close(self):\n",
    "        # Optional: implement any necessary cleanup\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the environment with users and products\n",
    "env = RecommendationEnv(users=customers, products=products, top_k=5, max_price=max_price)\n",
    "\n",
    "# Wrap the environment for vectorized training\n",
    "vec_env = make_vec_env(lambda: env, n_envs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom callback to log rewards for plotting\n",
    "class RewardLoggingCallback(BaseCallback):\n",
    "    def __init__(self, log_file=\"training_rewards.csv\", verbose=0):\n",
    "        super(RewardLoggingCallback, self).__init__(verbose)\n",
    "        self.rewards = []\n",
    "        self.episode_lengths = []  # Track episode lengths\n",
    "        self.current_episode_length = 0\n",
    "        self.log_file = log_file\n",
    "\n",
    "        # Open the file in write mode and add a header row for the CSV log\n",
    "        with open(self.log_file, mode=\"w\", newline=\"\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Timestep\", \"Reward\"])\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Get reward and done\n",
    "        reward = self.locals.get(\"rewards\")\n",
    "        done = self.locals.get(\"dones\")\n",
    "\n",
    "        if reward is not None:\n",
    "            reward_value = reward[0]  # Since there's only one environment\n",
    "            self.rewards.append(reward_value)\n",
    "\n",
    "            # Append the reward and timestep to the CSV file\n",
    "            with open(self.log_file, mode=\"a\", newline=\"\") as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow([self.num_timesteps, reward_value])\n",
    "\n",
    "        if done is not None:\n",
    "            if done[0]:\n",
    "                self.episode_lengths.append(self.current_episode_length)\n",
    "                self.current_episode_length = 0\n",
    "            else:\n",
    "                self.current_episode_length += 1\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output directory\n",
    "output_dir = \"./outputs/\"\n",
    "\n",
    "# Set up TensorBoard logging directory\n",
    "tensorboard_log_dir = f\"{output_dir}tensorboard_logs/\"\n",
    "model_save_path = f\"{output_dir}ppo_recommender\"\n",
    "os.makedirs(tensorboard_log_dir, exist_ok=True)\n",
    "\n",
    "# Configure TensorBoard logger\n",
    "new_logger = configure(tensorboard_log_dir, [\"tensorboard\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_kwargs = dict(\n",
    "    net_arch=[dict(pi=[256, 256], vf=[256, 256])],\n",
    "    activation_fn=nn.ReLU,\n",
    ")\n",
    "\n",
    "model = PPO(\n",
    "    policy=\"MultiInputPolicy\",\n",
    "    env=vec_env,\n",
    "    verbose=1,\n",
    "    learning_rate=3e-4,\n",
    "    batch_size=64,\n",
    "    n_steps=2048,\n",
    "    gamma=0.99,\n",
    "    gae_lambda=0.95,\n",
    "    ent_coef=0.0,\n",
    "    tensorboard_log=tensorboard_log_dir,\n",
    "    policy_kwargs=policy_kwargs,\n",
    ")\n",
    "\n",
    "model.set_logger(new_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize custom callbacks\n",
    "total_timesteps = 100000\n",
    "\n",
    "# Callbacks for logging rewards and epsilon values\n",
    "reward_callback = RewardLoggingCallback(log_file=f\"{output_dir}training_rewards.csv\")\n",
    "# epsilon_callback = EpsilonLoggingCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with both progress and reward logging callbacks\n",
    "model.learn(\n",
    "    total_timesteps=total_timesteps,\n",
    "    callback=[\n",
    "        reward_callback,\n",
    "        # epsilon_callback\n",
    "    ],\n",
    "    progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting training rewards over timesteps\n",
    "def plot_training_metrics(rewards):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(rewards, label=\"Reward\")\n",
    "    plt.xlabel(\"Timesteps\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.title(\"Reward vs. Timesteps\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Cumulative reward plot\n",
    "def plot_cumulative_rewards(rewards):\n",
    "    cumulative_rewards = np.cumsum(rewards)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(cumulative_rewards, label=\"Cumulative Reward\")\n",
    "    plt.xlabel(\"Timesteps\")\n",
    "    plt.ylabel(\"Cumulative Reward\")\n",
    "    plt.title(\"Cumulative Reward vs. Timesteps\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Moving average of rewards\n",
    "def plot_moving_average_rewards(rewards, window=50):\n",
    "    moving_avg_rewards = np.convolve(rewards, np.ones(window) / window, mode=\"valid\")\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(moving_avg_rewards, label=\"Moving Average Reward (Window = {})\".format(window))\n",
    "    plt.xlabel(\"Timesteps\")\n",
    "    plt.ylabel(\"Moving Average Reward\")\n",
    "    plt.title(\"Moving Average of Reward vs. Timesteps\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Plot episode lengths\n",
    "def plot_episode_lengths(episode_lengths):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(episode_lengths, label=\"Episode Length\")\n",
    "    plt.xlabel(\"Episodes\")\n",
    "    plt.ylabel(\"Episode Length\")\n",
    "    plt.title(\"Episode Length vs. Episodes\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training rewards\n",
    "plot_training_metrics(reward_callback.rewards)\n",
    "\n",
    "# Plot cumulative rewards\n",
    "plot_cumulative_rewards(reward_callback.rewards)\n",
    "\n",
    "# Plot moving average of rewards\n",
    "plot_moving_average_rewards(reward_callback.rewards)\n",
    "\n",
    "# Plot episode lengths\n",
    "plot_episode_lengths(reward_callback.episode_lengths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
