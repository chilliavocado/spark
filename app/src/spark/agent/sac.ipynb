{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import ast\n",
    "from datetime import datetime\n",
    "from enum import Enum\n",
    "from typing import List, Optional\n",
    "import gym\n",
    "from gym import spaces\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.logger import configure\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Model Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractionType(Enum):\n",
    "    \"\"\"\n",
    "    Enum for different types of interactions a customer can have.\n",
    "    \"\"\"\n",
    "\n",
    "    NONE = \"none\"\n",
    "    VIEW = \"view\"\n",
    "    LIKE = \"like\"\n",
    "    BUY = \"buy\"\n",
    "    RATE = \"rate\"\n",
    "    EXIT = \"exit\"\n",
    "    SESSION_START = \"session_start\"\n",
    "    SESSION_CLOSE = \"session_close\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Interaction:\n",
    "    \"\"\"\n",
    "    Represents a single interaction between a customer and a product.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        idx: str,\n",
    "        timestamp: datetime,\n",
    "        customer_idx: int,\n",
    "        product_idx: int,\n",
    "        type: InteractionType,\n",
    "        value: Optional[float] = None,\n",
    "        review_score: Optional[int] = None,\n",
    "        city_embedding: Optional[List[float]] = None,\n",
    "        state_embedding: Optional[List[float]] = None,\n",
    "        zip_code_embedding: Optional[List[float]] = None,\n",
    "        product_purchase_history: Optional[List[float]] = None,\n",
    "        category_purchase_history: Optional[List[float]] = None,\n",
    "        rate_history: Optional[List[float]] = None,\n",
    "    ) -> None:\n",
    "        self.idx = idx\n",
    "        self.timestamp = timestamp\n",
    "        self.customer_idx = customer_idx\n",
    "        self.product_idx = product_idx\n",
    "        self.type = type\n",
    "        self.value = value\n",
    "        self.review_score = review_score\n",
    "        self.city_embedding = city_embedding\n",
    "        self.state_embedding = state_embedding\n",
    "        self.zip_code_embedding = zip_code_embedding\n",
    "        self.product_purchase_history = product_purchase_history\n",
    "        self.category_purchase_history = category_purchase_history\n",
    "        self.rate_history = rate_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Customer:\n",
    "    def __init__(self, idx: int, zip_code: int, city: str, state: str, interactions: Optional[List[Interaction]] = None) -> None:\n",
    "        self.idx = idx\n",
    "        self.zip_code = zip_code\n",
    "        self.city = city\n",
    "        self.state = state\n",
    "        self.interactions = interactions if interactions is not None else []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Category:\n",
    "    def __init__(self, idx: int, name: str, desc: str) -> None:\n",
    "        self.idx = idx\n",
    "        self.name = name\n",
    "        self.desc = desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Product:\n",
    "    def __init__(self, idx: int, name: str, desc: str, long_desc: str, category: Category, price: float) -> None:\n",
    "        self.idx = idx\n",
    "        self.name = name\n",
    "        self.desc = desc\n",
    "        self.long_desc = long_desc\n",
    "        self.category = category\n",
    "        self.price = price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_customers(idxs: List[int] = [], include_interactions: bool = False) -> List[Customer]:\n",
    "    \"\"\"\n",
    "    Loads customer data from a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    - idxs: List of customer indices to load.\n",
    "    - include_interactions: Whether to include interactions data.\n",
    "\n",
    "    Returns:\n",
    "    - List of Customer objects.\n",
    "    \"\"\"\n",
    "    customer_df = pd.read_csv(\"../data/preprocessed_data/Customer.csv\")\n",
    "    interaction_df = pd.read_csv(\"../data/preprocessed_data/Interaction.csv\") if include_interactions else None\n",
    "\n",
    "    if idxs:\n",
    "        customer_df = customer_df[customer_df[\"idx\"].isin(idxs)]\n",
    "\n",
    "    customers = []\n",
    "    for _, row in tqdm(customer_df.iterrows(), total=len(customer_df), desc=\"Loading Customers\"):\n",
    "        interactions = []\n",
    "        if include_interactions:\n",
    "            customer_interactions = interaction_df[interaction_df[\"customer_idx\"] == row[\"idx\"]]\n",
    "            for _, int_row in customer_interactions.iterrows():\n",
    "                interactions.append(\n",
    "                    Interaction(\n",
    "                        idx=int_row[\"idx\"],\n",
    "                        timestamp=datetime.strptime(int_row[\"timestamp\"], \"%Y-%m-%d %H:%M:%S\"),\n",
    "                        customer_idx=int_row[\"customer_idx\"],\n",
    "                        product_idx=int_row[\"product_idx\"],\n",
    "                        type=InteractionType(int_row[\"type\"]),\n",
    "                        value=int_row[\"value\"],\n",
    "                        review_score=int_row[\"review_score\"],\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        customers.append(Customer(idx=row[\"idx\"], zip_code=row[\"zip_code\"], city=row[\"city\"], state=row[\"state\"], interactions=interactions))\n",
    "    return customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_vector_field(field: str) -> List[float]:\n",
    "    \"\"\"\n",
    "    Parses a string representation of a list into an actual list.\n",
    "\n",
    "    Parameters:\n",
    "    - field: String representation of a list.\n",
    "\n",
    "    Returns:\n",
    "    - List of floats.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return ast.literal_eval(field) if field else []\n",
    "    except (ValueError, SyntaxError):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_interactions(idxs: List[int] = [], customer_idxs: List[int] = [], k: int = 0) -> List[Interaction]:\n",
    "    \"\"\"\n",
    "    Loads interaction data from a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    - idxs: List of interaction indices to load.\n",
    "    - customer_idxs: List of customer indices to filter interactions.\n",
    "    - k: Number of interactions to load.\n",
    "\n",
    "    Returns:\n",
    "    - List of Interaction objects.\n",
    "    \"\"\"\n",
    "    interaction_df = pd.read_csv(\"../data/preprocessed_data/Customer_Interactions.csv\")\n",
    "\n",
    "    if idxs:\n",
    "        interaction_df = interaction_df[interaction_df[\"idx\"].isin(idxs)]\n",
    "    elif customer_idxs:\n",
    "        interaction_df = interaction_df[interaction_df[\"customer_idx\"].isin(customer_idxs)]\n",
    "\n",
    "    if k > 0:\n",
    "        interaction_df = interaction_df.sort_values(by=\"timestamp\", ascending=False).head(k)\n",
    "\n",
    "    interactions = []\n",
    "    for _, row in tqdm(interaction_df.iterrows(), total=len(interaction_df), desc=\"Loading Interactions\"):\n",
    "        interactions.append(\n",
    "            Interaction(\n",
    "                idx=row[\"idx\"],\n",
    "                timestamp=datetime.strptime(row[\"timestamp\"], \"%Y-%m-%d %H:%M:%S\"),\n",
    "                customer_idx=row[\"customer_idx\"],\n",
    "                product_idx=row[\"product_idx\"],\n",
    "                type=InteractionType(row[\"type\"]),\n",
    "                value=row[\"value\"],\n",
    "                review_score=row[\"review_score\"],\n",
    "                city_embedding=parse_vector_field(row[\"city_embedding\"]),\n",
    "                state_embedding=parse_vector_field(row[\"state_embedding\"]),\n",
    "                zip_code_embedding=parse_vector_field(row[\"zip_code_embedding\"]),\n",
    "                product_purchase_history=parse_vector_field(row[\"product_purchase_history\"]),\n",
    "                category_purchase_history=parse_vector_field(row[\"category_purchase_history\"]),\n",
    "                rate_history=parse_vector_field(row[\"rate_history\"]),\n",
    "            )\n",
    "        )\n",
    "    return interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_interactions(interactions: List[Interaction]):\n",
    "    \"\"\"\n",
    "    Stores interactions data back to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    - interactions: List of Interaction objects.\n",
    "    \"\"\"\n",
    "    interaction_data = [\n",
    "        {\n",
    "            \"idx\": i.idx,\n",
    "            \"timestamp\": i.timestamp.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"customer_idx\": i.customer_idx,\n",
    "            \"product_idx\": i.product_idx,\n",
    "            \"type\": i.type.value,\n",
    "            \"value\": i.value,\n",
    "            \"review_score\": i.review_score,\n",
    "        }\n",
    "        for i in interactions\n",
    "    ]\n",
    "    interaction_df = pd.DataFrame(interaction_data)\n",
    "    interaction_df.to_csv(\"../data/preprocessed_data/Interaction.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_categories(idxs: List[int] = []) -> List[Category]:\n",
    "    \"\"\"\n",
    "    Loads category data from a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    - idxs: List of category indices to load.\n",
    "\n",
    "    Returns:\n",
    "    - List of Category objects.\n",
    "    \"\"\"\n",
    "    category_df = pd.read_csv(\"../data/preprocessed_data/Category.csv\")\n",
    "    if idxs:\n",
    "        category_df = category_df[category_df[\"idx\"].isin(idxs)]\n",
    "\n",
    "    categories = [Category(idx=row[\"idx\"], name=row[\"name\"], desc=row[\"desc\"]) for _, row in category_df.iterrows()]\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_products(idxs: List[int] = []) -> List[Product]:\n",
    "    \"\"\"\n",
    "    Loads product data from a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    - idxs: List of product indices to load.\n",
    "\n",
    "    Returns:\n",
    "    - List of Product objects.\n",
    "    \"\"\"\n",
    "    product_df = pd.read_csv(\"../data/preprocessed_data/Product.csv\")\n",
    "    category_df = pd.read_csv(\"../data/preprocessed_data/Category.csv\")\n",
    "\n",
    "    category_map = {row[\"idx\"]: Category(idx=row[\"idx\"], name=row[\"name\"], desc=row[\"desc\"]) for _, row in category_df.iterrows()}\n",
    "\n",
    "    if idxs:\n",
    "        product_df = product_df[product_df[\"idx\"].isin(idxs)]\n",
    "\n",
    "    products = []\n",
    "    for _, row in product_df.iterrows():\n",
    "        category = category_map.get(row[\"category_num_id\"])\n",
    "        products.append(Product(idx=row[\"idx\"], name=row[\"name\"], desc=row[\"desc\"], long_desc=row[\"long_desc\"], category=category, price=row[\"price\"]))\n",
    "    return products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load interaction data and product data\n",
    "interactions = load_interactions()\n",
    "products = [p.idx for p in load_products()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommendationEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Custom Environment for a recommendation system using reinforcement learning.\n",
    "\n",
    "    The environment simulates a user's interaction with a recommendation system,\n",
    "    using the user's history and embeddings to generate observations, and\n",
    "    calculates rewards based on the agent's recommended products.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, interactions_data: List[dict], products_data: List[int], top_k: int = 5):\n",
    "        super(RecommendationEnv, self).__init__()\n",
    "        self.interactions_data = interactions_data\n",
    "        self.products_data = products_data\n",
    "        self.top_k = top_k\n",
    "        self.current_interaction_idx = 0\n",
    "\n",
    "        # Define action space for SAC (continuous action space)\n",
    "        self.action_space = spaces.Box(low=-1, high=1, shape=(top_k,), dtype=np.float32)\n",
    "\n",
    "        # Dynamic shapes based on the length of vectorized fields in the Interaction objects\n",
    "        example_interaction = interactions_data[0]\n",
    "        self.city_embedding_dim = len(example_interaction.city_embedding) if example_interaction.city_embedding else 12\n",
    "        self.state_embedding_dim = len(example_interaction.state_embedding) if example_interaction.state_embedding else 12\n",
    "        self.zip_code_embedding_dim = len(example_interaction.zip_code_embedding) if example_interaction.zip_code_embedding else 12\n",
    "        self.purchase_history_dim = len(example_interaction.product_purchase_history) if example_interaction.product_purchase_history else len(products_data)\n",
    "\n",
    "        # Define observation space with dynamically determined shapes\n",
    "        self.observation_space = spaces.Dict(\n",
    "            {\n",
    "                \"product_purchase_history\": spaces.Box(low=0, high=1, shape=(self.purchase_history_dim,), dtype=np.float32),\n",
    "                \"category_purchase_history\": spaces.Box(low=0, high=1, shape=(self.purchase_history_dim,), dtype=np.float32),\n",
    "                \"rate_history\": spaces.Box(low=0, high=5, shape=(self.purchase_history_dim,), dtype=np.float32),\n",
    "                \"city_embedding\": spaces.Box(low=0, high=1, shape=(self.city_embedding_dim,), dtype=np.float32),\n",
    "                \"state_embedding\": spaces.Box(low=0, high=1, shape=(self.state_embedding_dim,), dtype=np.float32),\n",
    "                \"zip_code_embedding\": spaces.Box(low=0, high=1, shape=(self.zip_code_embedding_dim,), dtype=np.float32),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Reward mapping for different interaction types\n",
    "        self.reward_mapping = {\n",
    "            \"buy\": 5.0,  # High reward for purchase\n",
    "            \"rate\": 3.0,  # Moderate reward for rating\n",
    "            \"like\": 2.0,  # Lower reward for like\n",
    "            \"view\": 1.0,  # Minimal reward for view\n",
    "            \"none\": -1.0,  # Penalty for no interaction\n",
    "            \"exit\": -2.0,  # Penalty for exit or negative feedback\n",
    "        }\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        \"\"\"Sets the random seed for the environment.\"\"\"\n",
    "        self._seed = seed\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Resets the environment to an initial state and returns an initial observation.\"\"\"\n",
    "        self.current_interaction_idx = np.random.randint(len(self.interactions_data))\n",
    "        return self._get_observation()\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Executes one time step within the environment.\n",
    "\n",
    "        Parameters:\n",
    "        - action: The action taken by the agent.\n",
    "\n",
    "        Returns:\n",
    "        - obs: The next observation.\n",
    "        - reward: The reward received.\n",
    "        - done: Whether the episode has ended.\n",
    "        - info: Additional information.\n",
    "        \"\"\"\n",
    "        # Convert continuous actions to discrete product indices\n",
    "        recommended_products = np.clip((action + 1) * (len(self.products_data) / 2), 0, len(self.products_data) - 1).astype(int)\n",
    "        recommended_products = recommended_products[: self.top_k]\n",
    "\n",
    "        # Select current interaction and simulate a response\n",
    "        interaction = self.interactions_data[self.current_interaction_idx]\n",
    "        simulated_response = self._simulate_user_response(interaction, recommended_products)\n",
    "\n",
    "        # Assign reward based on simulated user response\n",
    "        reward = self.reward_mapping.get(simulated_response, 0.0)\n",
    "\n",
    "        # Update index and check if the session is done\n",
    "        self.current_interaction_idx = (self.current_interaction_idx + 1) % len(self.interactions_data)\n",
    "        done = simulated_response == \"exit\"  # End episode if user exits\n",
    "\n",
    "        obs = self._get_observation()\n",
    "        return obs, reward, done, {}\n",
    "\n",
    "    def _simulate_user_response(self, interaction, recommended_products):\n",
    "        \"\"\"\n",
    "        Simulates a user response based on interaction history and recommended products.\n",
    "\n",
    "        This is a simplified function where the response type is randomly chosen for demonstration.\n",
    "        In a real system, it would be influenced by actual interaction patterns.\n",
    "        \"\"\"\n",
    "        # Randomly simulate a response; replace this with a model-based response if available\n",
    "        return np.random.choice([\"buy\", \"rate\", \"like\", \"view\", \"none\", \"exit\"])\n",
    "\n",
    "    def _get_observation(self):\n",
    "        \"\"\"Retrieves the current observation based on the current interaction.\"\"\"\n",
    "        interaction = self.interactions_data[self.current_interaction_idx]\n",
    "        obs = {\n",
    "            \"product_purchase_history\": np.array(interaction.product_purchase_history or np.zeros(self.purchase_history_dim), dtype=np.float32),\n",
    "            \"category_purchase_history\": np.array(interaction.category_purchase_history or np.zeros(self.purchase_history_dim), dtype=np.float32),\n",
    "            \"rate_history\": np.array(interaction.rate_history or np.zeros(self.purchase_history_dim), dtype=np.float32),\n",
    "            \"city_embedding\": np.array(interaction.city_embedding or np.zeros(self.city_embedding_dim), dtype=np.float32),\n",
    "            \"state_embedding\": np.array(interaction.state_embedding or np.zeros(self.state_embedding_dim), dtype=np.float32),\n",
    "            \"zip_code_embedding\": np.array(interaction.zip_code_embedding or np.zeros(self.zip_code_embedding_dim), dtype=np.float32),\n",
    "        }\n",
    "        return obs\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        \"\"\"Renders the environment (for debugging purposes).\"\"\"\n",
    "        print(f\"Current Interaction Index: {self.current_interaction_idx}\")\n",
    "        print(f\"Recommended Product Indices: {self.products_data}\")\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Performs any necessary cleanup.\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the environment\n",
    "env = RecommendationEnv(interactions_data=interactions, products_data=products, top_k=5)\n",
    "\n",
    "# Wrap the environment for vectorized training\n",
    "vec_env = make_vec_env(lambda: env, n_envs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom callback to update tqdm progress\n",
    "class TQDMProgressBarCallback(BaseCallback):\n",
    "    def __init__(self, total_timesteps, verbose=0):\n",
    "        super(TQDMProgressBarCallback, self).__init__(verbose)\n",
    "        self.total_timesteps = total_timesteps\n",
    "        self.progress_bar = None\n",
    "\n",
    "    def _on_training_start(self) -> None:\n",
    "        # Initialize tqdm progress bar at the start of training\n",
    "        self.progress_bar = tqdm(total=self.total_timesteps, desc=\"Training Progress\")\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Update progress bar by the number of timesteps\n",
    "        self.progress_bar.update(self.num_timesteps - self.progress_bar.n)\n",
    "        return True\n",
    "\n",
    "    def _on_training_end(self) -> None:\n",
    "        # Close the progress bar at the end of training\n",
    "        self.progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom callback to log rewards for plotting\n",
    "class RewardLoggingCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super(RewardLoggingCallback, self).__init__(verbose)\n",
    "        self.rewards = []\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Append the latest reward to rewards list\n",
    "        if \"reward\" in self.locals:\n",
    "            self.rewards.append(self.locals[\"reward\"].item())\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up TensorBoard logging directory\n",
    "tensorboard_log_dir = \"./tensorboard_logs/\"\n",
    "os.makedirs(tensorboard_log_dir, exist_ok=True)\n",
    "\n",
    "# Configure TensorBoard logger\n",
    "new_logger = configure(tensorboard_log_dir, [\"tensorboard\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SAC model with TensorBoard logging\n",
    "model = SAC(\"MultiInputPolicy\", vec_env, verbose=1, policy_kwargs=dict(net_arch=[256, 256]), tensorboard_log=tensorboard_log_dir)\n",
    "model.set_logger(new_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize custom callbacks\n",
    "total_timesteps = 100000\n",
    "reward_callback = RewardLoggingCallback()\n",
    "progress_callback = TQDMProgressBarCallback(total_timesteps=total_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with both progress and reward logging callbacks\n",
    "model.learn(total_timesteps=total_timesteps, callback=[progress_callback, reward_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save(\"sac_recommendation_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting training metrics\n",
    "def plot_training_metrics(rewards):\n",
    "    # Plot rewards over timesteps\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(rewards, label=\"Reward\")\n",
    "    plt.xlabel(\"Timesteps\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.title(\"Reward vs. Timesteps\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the rewards collected from callback\n",
    "plot_training_metrics(reward_callback.rewards)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
